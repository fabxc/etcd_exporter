speaking of exporting stuff - I wrote one for etcd: https://github.com/fabxc/etcd_exporter 
Any thoughts on exporting all nodes from a single exporting server? 
bbrazil
what sort of stats does etcd have? 
all those _total should be counters 
and those summaryvecs should be gauges 
as they're gauges of latency, rather than events 
are there totals available rather than rates? 
I think you'd go for one exporter per server 
fabxc
bbrazil: thanks for looking into it 
available stats: https://coreos.com/docs/distributed-configuration/etcd-api/#statistics 
bbrazil
bah, rates are annoying as they're always going to have artifacts 
fabxc
yes, they should be counters, but as we receive the absolute value it seemed like overhead to use them (haproxy_exporter does it the same way IIRC) 
bbrazil
you want to get monotonic counters where you can 
there's additional races otherwise 
fabxc
okay, I'll change that 
bbrazil
what exactly is the semantics of "latency"? 
for the leader followers 
bbrazil
you'll want to use a label other than 'instance' for the followers 
'follower' maybe? 
→ tsenart has joined 
fabxc
afaik, latency is simply the time of one roundtrip 
bbrazil
so what does 'current' mean? The last one? 
fabxc
jup 
bbrazil
that's not the best named, how about 'avg' - average latency since process start? 
fabxc
yes 
bbrazil
okay, so those metrics aren't too much use then 
← tsenart has quit (Ping timeout: 250 seconds) 
bbrazil
hmm, just put out the last value as follower_latency_last_milliseconds as a gauge I'd say 
fabxc
That's roughly what I had yesterday but it was suggested to include the rest as well - I might have been unclear, though. 
bbrazil
min and max may be useful, the others will just be confusing 
fabxc
okay, thanks for the input 
bbrazil
what's the 'state' label? 
fabxc
follower/leader 
bbrazil
that'll make the timeseries change their labels every time the leader changes - which you want to avoid 
have a gauge that's 1/0 for leader/follower 
fabxc
good idea 
bbrazil
one advantage of one exporter per etcd is that you can use the procfs module to get you cpu/ram stats 
bbrazil
for func (m *storeMetrics) set, you may want an 'operation' label for create/delete/gets. Not sure about expire, that sounds separate (and the _count is redundant) 
it's also tend to be bit easier to work with if you have failure+total rather than success+failure - but don't do that if there's the potential for wraparound 
bbrazil
it'd be great if we could get this all in to the main prometheus org 
fabxc
what about the global stats - only one exporter must expose those (otherwise panic) 
bbrazil
which are those? 
fabxc
the etcd leader can do this but if the leader switches there is no real guarantee that the unregister/register in order 
the modifying operation counters (set,update,delete) plus all of leaderStats 
bbrazil
those should be split out by node 
montioring masters is a bit tricky 
fabxc
etcd only provides per-node counters for get 
bbrazil
you mean the storeMetrics? 
fabxc
yes - currently they are all exported per node, there's a TODO though. 
bbrazil
just reading it 
I'd do it per node and take an average I duess 
*guess 
if you're worried about the number of timeseries just have the leader(s) push it out, but still break it out with a node label 
fabxc
okay great - lots of input, thanks. I'll look into it later or tomorrow. 
fabxc
would you keep an optional single-exporter mode (minus the nodes' process stats) or strictly enforce one exporter per node? 
bbrazil
as much as I think single-exporter mode is the One True Way(tm), I expect many will only use if there's single-exporter mode 
bbrazil
I'd suggest adding a etcd_scrape_duration_seconds gauge broken out by node, useful for spotting if a node is sluggish 
e.g. https://github.com/prometheus/jmx_exporter/blob/master/collector/src/main/java/io/prometheus/jmx/Jmx... 